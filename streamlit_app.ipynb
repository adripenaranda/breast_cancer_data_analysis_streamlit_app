{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and scaler\n",
    "model = load_model('model.keras')\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 08:52:05.194 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\adria\\Documents\\assignment_4_ann\\venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streamlit app title\n",
    "st.title(\"Breast Cancer Prediction App\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User inputs for model features\n",
    "st.sidebar.header(\"Input Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_features():\n",
    "    mean_radius = st.sidebar.slider(\"Mean Radius\", 6.0, 30.0, 14.0)\n",
    "    mean_perimeter = st.sidebar.slider(\"Mean Perimeter\", 40.0, 200.0, 90.0)\n",
    "    mean_area = st.sidebar.slider(\"Mean Area\", 140.0, 2500.0, 700.0)\n",
    "    mean_concavity = st.sidebar.slider(\"Mean Concavity\", 0.0, 0.5, 0.1)\n",
    "    mean_concave_points = st.sidebar.slider(\"Mean Concave Points\", 0.0, 0.3, 0.1)\n",
    "    worst_radius = st.sidebar.slider(\"Worst Radius\", 10.0, 40.0, 20.0)\n",
    "    worst_perimeter = st.sidebar.slider(\"Worst Perimeter\", 50.0, 300.0, 140.0)\n",
    "    worst_area = st.sidebar.slider(\"Worst Area\", 200.0, 5000.0, 1500.0)\n",
    "    worst_concavity = st.sidebar.slider(\"Worst Concavity\", 0.0, 1.5, 0.5)\n",
    "    worst_concave_points = st.sidebar.slider(\"Worst Concave Points\", 0.0, 0.5, 0.2)\n",
    "    \n",
    "    data = {\n",
    "        'mean radius': mean_radius,\n",
    "        'mean perimeter': mean_perimeter,\n",
    "        'mean area': mean_area,\n",
    "        'mean concavity': mean_concavity,\n",
    "        'mean concave points': mean_concave_points,\n",
    "        'worst radius': worst_radius,\n",
    "        'worst perimeter': worst_perimeter,\n",
    "        'worst area': worst_area,\n",
    "        'worst concavity': worst_concavity,\n",
    "        'worst concave points': worst_concave_points\n",
    "    }\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "\n",
    "input_df = user_input_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the input features match the scaler's expected order\n",
    "selected_features = [\n",
    "    'mean radius', 'mean perimeter', 'mean area', 'mean concavity', \n",
    "    'mean concave points', 'worst radius', 'worst perimeter', \n",
    "    'worst area', 'worst concavity', 'worst concave points'\n",
    "]\n",
    "\n",
    "input_df = input_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input features\n",
    "scaled_input = scaler.transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "prediction = model.predict(scaled_input)\n",
    "\n",
    "# Output prediction\n",
    "st.subheader('Prediction')\n",
    "if prediction[0][0] > 0.5:\n",
    "    st.write(\"Malignant\")\n",
    "else:\n",
    "    st.write(\"Benign\")\n",
    "\n",
    "st.subheader('Prediction Probability')\n",
    "st.write(prediction[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
